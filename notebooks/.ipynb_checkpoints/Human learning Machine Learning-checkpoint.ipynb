{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991121f8",
   "metadata": {},
   "source": [
    "# MENuS\n",
    "## Using Machine Learning to select the best algorithm\n",
    "* Define the features.\n",
    "* Include the ingredients generator.\n",
    "    * Generate an Instance of Ingredients list.\n",
    "* Finish the model.\n",
    "* Use minizinc from python.\n",
    "    * Run it with 3 Algorithms.\n",
    "    * Add the Instance to the Instances List.\n",
    "    * Add the time it takes for each Algorithm to the Time Execution Matrix.\n",
    "    * Transform the Instances List into the Features Array.\n",
    "    * Travel through the Time Execution Matrix and pick the Algorithms with faster results for each Instance.\n",
    "    * The Algorithm with the fastest result will be added to the Labels list.\n",
    "\n",
    "|  | Alg1 | Alg2 | Alg3 |\n",
    "| --- | --- | --- | --- |\n",
    "| Ins1 | X | Y | Z |\n",
    "| Ins2 | X | Y | Z |\n",
    "| Ins3 | X | Y | Z |\n",
    "   \n",
    "* Transform the ingredients list into the dataset for machine learning.\n",
    "    * Create the Ingredients list.\n",
    "    * Test with the minizinc model, all the Alg = 3 -> minizinc(300).\n",
    "    * Take and transform the one that takes less time.\n",
    "* Training the AI. Split dataset, 70% for training and 30% for prediction, at least 80% accuracy expected. \n",
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c199d6f",
   "metadata": {},
   "source": [
    "# Get the Ingredients List\n",
    "\n",
    "The instances have been generated using the notebook: Generate Instance.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1087b2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10;\n",
      "groceries = [|224,19,13,24,114,1740|316,27,27,25,128,2914|128,17,13,2,66,1703|384,5,61,30,90,1274|412,14,60,29,177,1176|336,3,55,26,158,957|312,11,13,54,61,3226|436,7,26,76,172,1685|380,13,33,49,52,3842|364,14,57,20,107,1374|];\n",
      "requirements = [|5031,6679|114,151|390,429|171,204|];\n"
     ]
    }
   ],
   "source": [
    "import os   \n",
    "import re\n",
    "\n",
    "instances_folder = '../instances'  \n",
    "instances = [os.path.join(instances_folder, f) for f in os.listdir(instances_folder) if f.endswith('.dzn')]\n",
    "for i in range(len(instances)):\n",
    "    with open(instances[i], encoding=\"utf8\") as file_object:\n",
    "        instances[i] = file_object.read()\n",
    "\n",
    "print(instances[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadad751",
   "metadata": {},
   "source": [
    "# Create Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18b6e5cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#-MINIZINC---------------------------------\n",
    "n_inst=len(instances)\n",
    "#ingredient_size=5\n",
    "il = instances\n",
    "tem = np.zeros((n_inst, 3))\n",
    "#-MACHINE LEARNING-------------------------\n",
    "q_features = 40\n",
    "features = np.zeros((n_inst, q_features))\n",
    "labels = np.zeros((n_inst), dtype=int)\n",
    "#------------------------------------------\n",
    "\n",
    "# Create Instances List:\n",
    "\"\"\"def create_IL(n, isz):\n",
    "    for i in range(0,n):\n",
    "        il.append(createDZN(isz))\"\"\"\n",
    "        \n",
    "# Create Time Execution Matrix:\n",
    "def create_TEM(n):\n",
    "    for i in range(n):\n",
    "        # Here there should be the Minizinc Time results.\n",
    "        tem[i, :] = np.random.rand(3) * 10\n",
    "    #print(\"\\nUpdated [tem].\\n\",tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b079165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_IL(n_inst,ingredient_size)\n",
    "create_TEM(n_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca092789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groceries(g_array):\n",
    "    data_groceries = []\n",
    "    for i in range(0, len(g_array)):\n",
    "        loop_groceries = g_array[i].split(\"groceries = [|\")\n",
    "        loop_groceries = loop_groceries[1].split(\"|];\\nrequirements\")\n",
    "        loop_groceries = loop_groceries[0].split(\"|\")\n",
    "        for j in range(0, len(loop_groceries)):\n",
    "            # Conversion from String to Int Array.\n",
    "            loop_groceries[j] = [int(x) for x in loop_groceries[j].split(\",\")]\n",
    "        data_groceries = data_groceries + [loop_groceries] \n",
    "    return np.array(data_groceries)\n",
    "\n",
    "np_groceries = get_groceries(il) \n",
    "\n",
    "def create_features(inst_array):\n",
    "    for i in range(0,n_inst):\n",
    "        # features: i in the left represents an Instance; 0,1... in the right represents a Feature.\n",
    "        # np_groceries: i in the left represents an Instance; \":\" represents all rows; 0,1... in the right represents a Macronutrient Column.\n",
    "        # 0: Calories. 1: Protein. 2: Carbo. 3: Fat. 4: Quantity. 5: Price.\n",
    "        features[i,0] = np.mean(np_groceries[i,:,0])\n",
    "        features[i,1] = np.median(np_groceries[i,:,0])\n",
    "        features[i,2] = np.std(np_groceries[i,:,0])\n",
    "        features[i,3] = np.var(np_groceries[i,:,0])\n",
    "        features[i,4] = np.min(np_groceries[i,:,0])\n",
    "        features[i,5] = np.max(np_groceries[i,:,0])\n",
    "        features[i,6] = np.argmin(np_groceries[i,:,0])\n",
    "        features[i,7] = np.argmax(np_groceries[i,:,0])\n",
    "        features[i,8] = np.percentile(np_groceries[i,:,0],25)\n",
    "        features[i,9] = np.percentile(np_groceries[i,:,0],75)\n",
    "        #----------------------------------------------------\n",
    "        features[i,10] = np.mean(np_groceries[i,:,1])\n",
    "        features[i,11] = np.median(np_groceries[i,:,1])\n",
    "        features[i,12] = np.std(np_groceries[i,:,1])\n",
    "        features[i,13] = np.var(np_groceries[i,:,1])\n",
    "        features[i,14] = np.min(np_groceries[i,:,1])\n",
    "        features[i,15] = np.max(np_groceries[i,:,1])\n",
    "        features[i,16] = np.argmin(np_groceries[i,:,1])\n",
    "        features[i,17] = np.argmax(np_groceries[i,:,1])\n",
    "        features[i,18] = np.percentile(np_groceries[i,:,1],25)\n",
    "        features[i,19] = np.percentile(np_groceries[i,:,1],75)\n",
    "        #----------------------------------------------------\n",
    "        features[i,20] = np.mean(np_groceries[i,:,2])\n",
    "        features[i,21] = np.median(np_groceries[i,:,2])\n",
    "        features[i,22] = np.std(np_groceries[i,:,2])\n",
    "        features[i,23] = np.var(np_groceries[i,:,2])\n",
    "        features[i,24] = np.min(np_groceries[i,:,2])\n",
    "        features[i,25] = np.max(np_groceries[i,:,2])\n",
    "        features[i,26] = np.argmin(np_groceries[i,:,2])\n",
    "        features[i,27] = np.argmax(np_groceries[i,:,2])\n",
    "        features[i,28] = np.percentile(np_groceries[i,:,2],25)\n",
    "        features[i,29] = np.percentile(np_groceries[i,:,2],75)                \n",
    "        #----------------------------------------------------\n",
    "        features[i,30] = np.mean(np_groceries[i,:,3])\n",
    "        features[i,31] = np.median(np_groceries[i,:,3])\n",
    "        features[i,32] = np.std(np_groceries[i,:,3])\n",
    "        features[i,33] = np.var(np_groceries[i,:,3])\n",
    "        features[i,34] = np.min(np_groceries[i,:,3])\n",
    "        features[i,35] = np.max(np_groceries[i,:,3])\n",
    "        features[i,36] = np.argmin(np_groceries[i,:,3])\n",
    "        features[i,37] = np.argmax(np_groceries[i,:,3])\n",
    "        features[i,38] = np.percentile(np_groceries[i,:,3],25)\n",
    "        features[i,39] = np.percentile(np_groceries[i,:,3],75) \n",
    "\n",
    "create_features(np_groceries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48481cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(n,m):\n",
    "    for i in range(0,n):\n",
    "        labels[i] = np.argmin(m[i])+1\n",
    "    \n",
    "create_labels(n_inst, tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "324167d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "X = features # Features\n",
    "y = labels # Labels\n",
    "\n",
    "# Normalize the data to have zero mean and unit variance\n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "X = np.where(std == 0, 0, (X - mean) / std)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train a machine learning model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80f816f2-7127-493f-8f8a-5924e91ad0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train a machine learning model on the training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037b99c-54fb-47d9-af35-e27c9dc629eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
