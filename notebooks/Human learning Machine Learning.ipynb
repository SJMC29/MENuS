{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991121f8",
   "metadata": {},
   "source": [
    "# MENuS\n",
    "## Using Machine Learning to select the best algorithm\n",
    "* Define the features.\n",
    "* Include the ingredients generator.\n",
    "    * Generate an Instance of Ingredients list.\n",
    "* Finish the model.\n",
    "* Use minizinc from python.\n",
    "    * Run it with 3 Algorithms.\n",
    "    * Add the Instance to the Instances List.\n",
    "    * Add the time it takes for each Algorithm to the Time Execution Matrix.\n",
    "    * Transform the Instances List into the Features Array.\n",
    "    * Travel through the Time Execution Matrix and pick the Algorithms with faster results for each Instance.\n",
    "    * The Algorithm with the fastest result will be added to the Labels list.\n",
    "\n",
    "|  | Alg1 | Alg2 | Alg3 |\n",
    "| --- | --- | --- | --- |\n",
    "| Ins1 | X | Y | Z |\n",
    "| Ins2 | X | Y | Z |\n",
    "| Ins3 | X | Y | Z |\n",
    "   \n",
    "* Transform the ingredients list into the dataset for machine learning.\n",
    "    * Create the Ingredients list.\n",
    "    * Test with the minizinc model, all the Alg = 3 -> minizinc(300).\n",
    "    * Take and transform the one that takes less time.\n",
    "* Training the AI. Split dataset, 70% for training and 30% for prediction, at least 80% accuracy expected. \n",
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3157e4ec-f829-4580-8d79-9e6e85dc239c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Auxiliar Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4a7ddcc8-d830-4df2-a339-a26989dc6d01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_red(text):\n",
    "    print('\\x1b[31m' + text + '\\x1b[0m')\n",
    "    \n",
    "def print_yellow(text):\n",
    "    print('\\x1b[33m' + text + '\\x1b[0m')\n",
    "\n",
    "def print_green(text):\n",
    "    print('\\x1b[32m' + text + '\\x1b[0m')\n",
    "\n",
    "def print_pink(text):\n",
    "    print('\\x1b[35m' + text + '\\x1b[0m')\n",
    "\n",
    "def print_cyan(text):\n",
    "    print('\\x1b[36m' + text + '\\x1b[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c199d6f",
   "metadata": {},
   "source": [
    "## Get the Instances / Ingredient list\n",
    "The instances have been generated using the notebook: Generate Instance.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1087b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "instances_folder = '..\\instances'\n",
    "instances_path = [os.path.join(instances_folder, f) for f in os.listdir(instances_folder) if f.endswith('.dzn')]\n",
    "instances = []\n",
    "for path in instances_path:\n",
    "    with open(path, encoding=\"utf8\") as file_object:\n",
    "        instances.append(file_object.read())\n",
    "#print(instances_path[1])\n",
    "#print(instances[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9fd74-957b-4b66-a019-84317519b781",
   "metadata": {},
   "source": [
    "# Minizinc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f2a2f-7bfe-4eb2-9b82-5d5d5067f410",
   "metadata": {},
   "source": [
    "### Chosen model with annotations\n",
    "The models have been generated using the notebook: GenerateAnnotations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5685c50e-8b65-49cb-b814-2b492d0d6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '../models/winners/smallest-indomain.mzn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822cd46-850a-4da2-80e8-dd283b5f1cb9",
   "metadata": {},
   "source": [
    "## Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d901e1cb-6138-418a-a678-ba19cff0da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = [\"HiGHS\", \"COIN-BC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4d10afea-b1de-4a63-8174-6806f38363b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import subprocess\n",
    "# Returns the solver who solved the model in the best way possible\n",
    "def solve_with_minizinc(instances, timeout_mzn, timeout):    \n",
    "    winner = [0] * len(instances) # 0 for HiGHS, 1 for COIN-BC\n",
    "    timeout_mzn = timeout_mzn*1000\n",
    "    \n",
    "    for i, instance in enumerate(instances):\n",
    "        mnt = float('inf')\n",
    "        time = float('inf')\n",
    "        for j, solver in enumerate(solvers):\n",
    "            # Run the minizinc command for the current model and data file  \n",
    "            cmd = f\"minizinc --solver {solver} --output-time {model} {instance} --output-time --solver-time-limit {timeout_mzn}\" \n",
    "            proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "            try: \n",
    "                # Get output from fzn\n",
    "                stdout, stderr = proc.communicate(timeout=timeout) \n",
    "                stdout = stdout.decode()\n",
    "                try:\n",
    "                    # Store value mnt (temp).\n",
    "                    start = stdout.find('mnt = ')+6\n",
    "                    end = stdout.find(';',start)\n",
    "                    mnt_temp = int(stdout[start:end])\n",
    "                    # Store value time (temp).\n",
    "                    time_temp = float(stdout.split(' ')[-2])\n",
    "                except:\n",
    "                    mnt_temp = float('inf')\n",
    "                    time_temp = float('inf')\n",
    "                print_green(f'{solver} with {instance} SOLVED with a value of {mnt_temp} in {time_temp:.2f} seconds.')\n",
    "\n",
    "            except subprocess.TimeoutExpired: \n",
    "                print_red(f'Error from minizinc: Stopping.')\n",
    "                mnt_temp = float('inf')\n",
    "                time_temp = float('inf')\n",
    "                if os.name == 'nt': # If the os is Windows\n",
    "                    subprocess.call(['taskkill', '/F', '/T', '/PID', str(proc.pid)]) # Force kill the process\n",
    "                else:\n",
    "                    os.killpg(os.getpgid(proc.pid), signal.SIGTERM) # Kill the process group\n",
    "\n",
    "            if mnt >= mnt_temp: # If the value is minor from the stored\n",
    "                if mnt == mnt_temp: # If the value is equal from the stored compare time\n",
    "                    if time >= time_temp: # If the value of time from minizinc is minor from the stored\n",
    "                        if time == time_temp: # If the value of time from minizinc is equal from the stored choose random\n",
    "                            winner[i] = random.randint(j-1,j)    \n",
    "                        else:\n",
    "                            mnt = mnt_temp\n",
    "                            time = time_temp\n",
    "                            winner[i] = j\n",
    "                else:\n",
    "                    mnt = mnt_temp\n",
    "                    time = time_temp\n",
    "                    winner[i] = j\n",
    "        print_yellow(str(winner[i])+\" WON!\")\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadad751",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## Get data: Parse ingredients list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c2ecd121-a23a-405b-8d80-7349aff3cda4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ingredients list\n",
    "def get_groceries(g_array):\n",
    "    data_groceries = []\n",
    "    for i in range(0, len(g_array)):\n",
    "        loop_groceries = g_array[i].split(\"groceries = [|\")\n",
    "        loop_groceries = loop_groceries[1].split(\"|];\\nrequirements\")\n",
    "        loop_groceries = loop_groceries[0].split(\"|\")\n",
    "        \n",
    "        for j in range(0, len(loop_groceries)):\n",
    "            # Conversion from String to Int Array.\n",
    "            loop_groceries[j] = [int(x) for x in loop_groceries[j].split(\",\")]\n",
    "            \n",
    "        data_groceries = data_groceries + [np.array(loop_groceries)]\n",
    "    return data_groceries\n",
    "\n",
    "def get_requirements(r_array):\n",
    "    data_requirements = []\n",
    "    for i in range(0, len(r_array)):\n",
    "        loop_requirements = r_array[i].split(\"requirements = [|\")\n",
    "        loop_requirements = loop_requirements[1].split(\"|];\")\n",
    "        loop_requirements = loop_requirements[0].split(\"|\")\n",
    "        \n",
    "        for j in range(0, len(loop_requirements)):\n",
    "            # Conversion from String to Int Array.\n",
    "            loop_requirements[j] = [int(x) for x in loop_requirements[j].split(\",\")]\n",
    "            \n",
    "        data_requirements = data_requirements + [np.array(loop_requirements)]\n",
    "    return data_requirements\n",
    "\n",
    "\n",
    "def create_features(instances):\n",
    "    q_features = 61\n",
    "    res = np.zeros((len(instances), q_features))    \n",
    "    np_groceries = get_groceries(instances)\n",
    "    np_requirements = get_requirements(instances)\n",
    "    print(np_groceries[0])\n",
    "    print(np_requirements[0])\n",
    "    \n",
    "    for i in range(0,len(instances)):\n",
    "        # features: i in the left represents an Instance; 0,1... in the right represents a Feature.\n",
    "        #----------------------------------------------------\n",
    "        # np_groceries: i in the left represents an Instance; \":\" represents all rows; 0,1... in the right represents a Macronutrient Column.\n",
    "        # 0: Calories. 1: Protein. 2: Carbo. 3: Fat. 4: Quantity. 5: Price.\n",
    "        \"\"\"res[i,0] = np.mean(np_groceries[i][:,0])\n",
    "        res[i,1] = np.median(np_groceries[i][:,0])\n",
    "        res[i,2] = np.std(np_groceries[i][:,0])\n",
    "        res[i,3] = np.var(np_groceries[i][:,0])\n",
    "        res[i,4] = np.min(np_groceries[i][:,0])\n",
    "        res[i,5] = np.max(np_groceries[i][:,0])\n",
    "        res[i,6] = np.argmin(np_groceries[i][:,0])\n",
    "        res[i,7] = np.argmax(np_groceries[i][:,0])\n",
    "        res[i,8] = np.percentile(np_groceries[i][:,0],25)\n",
    "        res[i,9] = np.percentile(np_groceries[i][:,0],75)\"\"\"\n",
    "        #----------------------------------------------------\n",
    "        res[i,0] = np.mean(np_groceries[i][:,1])\n",
    "        res[i,1] = np.median(np_groceries[i][:,1])\n",
    "        res[i,2] = np.std(np_groceries[i][:,1])\n",
    "        res[i,3] = np.var(np_groceries[i][:,1])\n",
    "        res[i,4] = np.min(np_groceries[i][:,1])\n",
    "        res[i,5] = np.max(np_groceries[i][:,1])\n",
    "        res[i,6] = np.argmin(np_groceries[i][:,1])\n",
    "        res[i,7] = np.argmax(np_groceries[i][:,1])\n",
    "        res[i,8] = np.percentile(np_groceries[i][:,1],25)\n",
    "        res[i,9] = np.percentile(np_groceries[i][:,1],75)\n",
    "        #----------------------------------------------------\n",
    "        res[i,10] = np.mean(np_groceries[i][:,2])\n",
    "        res[i,11] = np.median(np_groceries[i][:,2])\n",
    "        res[i,12] = np.std(np_groceries[i][:,2])\n",
    "        res[i,13] = np.var(np_groceries[i][:,2])\n",
    "        res[i,14] = np.min(np_groceries[i][:,2])\n",
    "        res[i,15] = np.max(np_groceries[i][:,2])\n",
    "        res[i,16] = np.argmin(np_groceries[i][:,2])\n",
    "        res[i,17] = np.argmax(np_groceries[i][:,2])\n",
    "        res[i,18] = np.percentile(np_groceries[i][:,2],25)\n",
    "        res[i,19] = np.percentile(np_groceries[i][:,2],75)                \n",
    "        #----------------------------------------------------\n",
    "        res[i,20] = np.mean(np_groceries[i][:,3])\n",
    "        res[i,21] = np.median(np_groceries[i][:,3])\n",
    "        res[i,22] = np.std(np_groceries[i][:,3])\n",
    "        res[i,23] = np.var(np_groceries[i][:,3])\n",
    "        res[i,24] = np.min(np_groceries[i][:,3])\n",
    "        res[i,25] = np.max(np_groceries[i][:,3])\n",
    "        res[i,26] = np.argmin(np_groceries[i][:,3])\n",
    "        res[i,27] = np.argmax(np_groceries[i][:,3])\n",
    "        res[i,28] = np.percentile(np_groceries[i][:,3],25)\n",
    "        res[i,29] = np.percentile(np_groceries[i][:,3],75)\n",
    "        #---------------------------------------------------\n",
    "        # np_requirements: i in the left represents an Instance; \":\" represents all rows; 0,1... in the right represents a Macronutrient Column.\n",
    "        # 0: Calories. 1: Protein. 2: Carbo. 3: Fat. 4: Quantity. 5: Price.\n",
    "        res[i,30] = np.mean(np_requirements[i][0,:])#$HERE\n",
    "        res[i,31] = np.median(np_requirements[i][:,1])\n",
    "        res[i,32] = np.std(np_requirements[i][:,1])\n",
    "        res[i,33] = np.var(np_requirements[i][:,1])\n",
    "        res[i,34] = np.min(np_requirements[i][:,1])\n",
    "        res[i,35] = np.max(np_requirements[i][:,1])\n",
    "        res[i,36] = np.argmin(np_requirements[i][:,1])\n",
    "        res[i,37] = np.argmax(np_requirements[i][:,1])\n",
    "        res[i,38] = np.percentile(np_requirements[i][:,1],25)\n",
    "        res[i,39] = np.percentile(np_requirements[i][:,1],75)\n",
    "        #----------------------------------------------------\n",
    "        res[i,40] = np.mean(np_requirements[i][:,2])\n",
    "        res[i,41] = np.median(np_requirements[i][:,2])\n",
    "        res[i,42] = np.std(np_requirements[i][:,2])\n",
    "        res[i,43] = np.var(np_requirements[i][:,2])\n",
    "        res[i,44] = np.min(np_requirements[i][:,2])\n",
    "        res[i,45] = np.max(np_requirements[i][:,2])\n",
    "        res[i,46] = np.argmin(np_requirements[i][:,2])\n",
    "        res[i,47] = np.argmax(np_requirements[i][:,2])\n",
    "        res[i,48] = np.percentile(np_requirements[i][:,2],25)\n",
    "        res[i,49] = np.percentile(np_requirements[i][:,2],75)                \n",
    "        #----------------------------------------------------\n",
    "        res[i,50] = np.mean(np_requirements[i][:,3])\n",
    "        res[i,51] = np.median(np_requirements[i][:,3])\n",
    "        res[i,52] = np.std(np_requirements[i][:,3])\n",
    "        res[i,53] = np.var(np_requirements[i][:,3])\n",
    "        res[i,54] = np.min(np_requirements[i][:,3])\n",
    "        res[i,55] = np.max(np_requirements[i][:,3])\n",
    "        res[i,56] = np.argmin(np_requirements[i][:,3])\n",
    "        res[i,57] = np.argmax(np_groceries[i][:,3])\n",
    "        res[i,58] = np.percentile(np_requirements[i][:,3],25)\n",
    "        res[i,59] = np.percentile(np_requirements[i][:,3],75)\n",
    "        #---------------------------------------------------\n",
    "        res[i,60] = len(np_groceries[i])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ddbcad-b0b7-4c5c-8b9f-b8943e1cbcfa",
   "metadata": {},
   "source": [
    "## Create Features\n",
    "## Create Labels\n",
    "Represents the solver that solved the model in the best way, comparing first the result and then the time. The best solver will be the one that solves the model with a minor value in less time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "18b6e5cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2050  100  120  130  116 3058]\n",
      " [2120   40   40  200   83 1864]\n",
      " [3006  180   45  234  123 1991]\n",
      " ...\n",
      " [ 800    5   15   80  184 2861]\n",
      " [2128   64  288   80  183 2473]\n",
      " [1593   72  144   81   62 3927]]\n",
      "[[29300 33924]\n",
      " [  760  1012]\n",
      " [ 4000  4400]\n",
      " [ 1140  1364]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstances\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[119], line 103\u001b[0m, in \u001b[0;36mcreate_features\u001b[1;34m(instances)\u001b[0m\n\u001b[0;32m    101\u001b[0m res[i,\u001b[38;5;241m39\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(np_requirements[i][:,\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m75\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m#----------------------------------------------------\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m res[i,\u001b[38;5;241m40\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mnp_requirements\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    104\u001b[0m res[i,\u001b[38;5;241m41\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(np_requirements[i][:,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    105\u001b[0m res[i,\u001b[38;5;241m42\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(np_requirements[i][:,\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "features = create_features(instances)\n",
    "#labels = solve_with_minizinc(instances_path, 10, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c861d-a5e3-4318-80d5-40ddaf2e2800",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "324167d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanj\\AppData\\Local\\Temp\\ipykernel_21924\\3942174831.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  X = np.where(std == 0, 0, (X - mean) / std)\n"
     ]
    }
   ],
   "source": [
    "X = features # Features\n",
    "y = labels # Labels\n",
    "\n",
    "# Normalize the data to have zero mean and unit variance\n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "X = np.where(std == 0, 0, (X - mean) / std)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train a machine learning model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "80f816f2-7127-493f-8f8a-5924e91ad0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Train a machine learning model on the training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f374d0d2-1de8-4a37-a733-96462d7ba210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[20 20]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "51556304-95c9-43a2-8db9-4079e9259a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 26 52.0%\n",
      "1: 24 48.0%\n"
     ]
    }
   ],
   "source": [
    "freq = {}\n",
    "\n",
    "# Count frequency of each element in the array\n",
    "for num in labels:\n",
    "    if num in freq:\n",
    "        freq[num] += 1\n",
    "    else:\n",
    "        freq[num] = 1\n",
    "\n",
    "# Print frequency of each element\n",
    "for num, count in freq.items():\n",
    "    print(f\"{num}: {count} {count/len(labels)*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22aea7-aa11-4ece-b617-977f47b1c92b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MENuS",
   "language": "python",
   "name": "menus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
